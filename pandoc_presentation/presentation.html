<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Emanuele Gentiletti">
  <title>Concrete Numeric Representations in LLM Embeddings</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/dist/reset.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/dist/theme/black.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Concrete Numeric Representations in LLM
Embeddings</h1>
  <p class="author">Emanuele Gentiletti</p>
</section>

<section id="what-is-a-concrete-representation" class="slide level1">
<h1>What is a Concrete Representation?</h1>
<ul>
<li><p>The hypothesis we explore is the presence of geometric structures
in the organization of numerical embeddings that facilitates
mathematical computations.</p></li>
<li><p>Precedent in humans: <strong>Savant Syndrome</strong></p>
<ul>
<li>Some people are able to perform extraordinary feats of mathematical
prowess with little effort.</li>
<li>It is proposed in the scientific literature that this ability
doesn‚Äôt come through algorithmic processes, but through the consultation
of encoded geometric structures that reveal the answer
<ul>
<li><strong>Concrete Representations</strong> according to Murray et
al., 2005 &lt;?&gt;</li>
</ul></li>
<li>Sequence-space synesthesia
<ul>
<li>Savants and Synasthetes are able to visualize sequences in space and
get answers to mathematical questions just by navigating them in space
<!----></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="llm-embeddings" class="slide level1">
<h1>LLM Embeddings</h1>
<p>!!!</p>
<ul>
<li>String is split in tokens, each token corresponds to a single vector
of weights in the first layer</li>
<li>Embeddings are trained through gradient descent, which changes the
weights to minimize a target error function</li>
</ul>
<p><img data-src="%22public/embeddings_example.png"
alt="Embeddings example" /> <!----></p>
</section>
<section id="bad-tokenization-schemes" class="slide level1">
<h1>Bad tokenization schemes</h1>
<ul>
<li>Most current LLMs tokenize numbers in an unintuitive way.
<ul>
<li>L2R tokenization: <span class="math inline">$\underbrace{123} \;
\underbrace{456} \; \underbrace{7}$</span></li>
<li>R2L tokenization: <span class="math inline">$\underbrace{1} \;
\underbrace{234} \; \underbrace{567}$</span></li>
</ul></li>
<li>R2L is preferrable for numeric computations (think doing additions
in column), so why do LLMs use L2R?
<ul>
<li>Reason: BPE algorithm</li>
</ul></li>
</ul>
<p><a href="https://tiktokenizer.vercel.app/">üîó Tiktokenizer</a>
<!----></p>
</section>
<section id="bpe-algorithm" class="slide level1">
<h1>BPE algorithm</h1>
<ul>
<li><p>We construct a list of tokens for the LLM to consider as ‚Äúunits‚Äù
to work with</p>
<ul>
<li>Start: each singular character gets a token (<code>a</code>,
<code>b</code>, <code>c</code>, ‚Ä¶)</li>
<li>Until we reach the target <code>vocabulary_size</code>: - Add the
most common occurring pair of tokens as a new token - For example, the
common preposition <code>to</code> is very common in English text, so it
may get added to the target vocabulary (<code>a</code>, <code>b</code>,
<code>c</code>, ‚Ä¶, <code>to</code>) - After some cycles, the most common
occorring pair of tokens might be <code>to</code> and <code>m</code> to
form the common name <code>tom</code> (<code>a</code>, <code>b</code>,
<code>c</code>, ‚Ä¶, <code>to</code>, ‚Ä¶, <code>tom</code>) - This is how
vocabularies in modern LLMs are built. <!----></li>
</ul></li>
<li><p>BPE constructs its vocabulary by associating tokens from left to
right.</p></li>
<li><p>Tokenizers split sentences according to the vocabulary with the
same logic (L2R).</p></li>
<li><p>GPT-2 and GPT-3 used the same criteria for numbers as it did for
words, leading to tokenization of only most frequently occurring numbers
!!!</p></li>
<li><p>Most open-source LLMs today always tokenize integers from 0 to
999 using a single token, but they still group tokens L2R (123,456,7)
<img data-src="%22public/unique_tokens.png%22"
alt="GPT-2 unique numeric tokens. A yellow square means the corresponding number is represented with a single token." />
<a
href="https://www.beren.io/2023-02-04-Integer-tokenization-is-insane/">üîó
beren.io - Integer Tokenization is Insane</a> <!----> # Bad Clustering
and Inference-time correction</p></li>
<li><p>A study has been conducted to benchmark addition performed with
both L2R and R2L clustering - üß™ Experiment: ask the same addition
problems twice - First time neutrally: 1234567 + 654321 - Second time
clustering digits with commas: 1,234,567 + 654,321 - Commas force token
separation at the point of insertion</p></li>
<li><p>R2L tokenization dramatically outperforms standard L2R
tokenization</p>
<ul>
<li>GPT-3.5: 75.6% accuracy (L2R) vs 97.8% accuracy (R2L)</li>
<li>GPT-4: 84.4% accuracy (L2R) vs 98.9% accuracy (R2L)</li>
</ul></li>
</ul>
<p><a href="https://arxiv.org/abs/2402.14903">üìö Tokenization counts:
the impact of tokenization on arithmetic in frontier LLMs</a> <!----> -
The models had been trained with a L2R tokenization scheme, yet forcing
a R2L one improves performance without needing to train the model
again</p>
<ul>
<li>The model weights appear to have learned arithmetic algorithms that
are fundamentally R2L-oriented, despite being trained predominantly on
L2R tokenized data.
<ul>
<li>Inductive biases emerge from mathematical structure, not just data
statistics &lt;?&gt;</li>
</ul></li>
<li>This is also a clue that the <strong>underlying embedding
representation of numbers is representative of general mathematical
principles</strong>, and not just rote memorization. <!----> # The
Platonic Representation Hypothesis</li>
</ul>
<p><a href="https://arxiv.org/abs/2405.07987">üìöHuh et al.¬†(2024)</a>
argue that all models are converging to a shared statistical model of
reality.</p>
<ul>
<li><strong>Vision-Vision Alignment</strong>
<ul>
<li>Tested 78 vision models of various architectures and training
objectives</li>
<li>Models with higher performance on VTAB tasks showed greater mutual
alignment</li>
<li>Competent models clustered together in representation space</li>
</ul></li>
<li><strong>Cross-Modal Alignment</strong>
<ul>
<li>Vision models and language models show increasing alignment as they
scale</li>
<li>Models can be ‚Äústitched‚Äù together across modalities with simple
learned mappings</li>
<li>Color representations learned from text match those learned from
images</li>
</ul></li>
<li><strong>Evidence from Model Stitching</strong>
<ul>
<li>Different models can have their intermediate layers successfully
swapped</li>
<li>This works even across different training objectives and
datasets</li>
<li>Success indicates compatible internal representations <!----> To
recap:</li>
</ul></li>
<li>Concrete structures can provide Savants and synaesthetes access to
mathematical knowledge</li>
<li>LLMs generalize over mathematical concepts even when they‚Äôre trained
wrongly</li>
<li>Representations in LLMs seem to be converging</li>
</ul>
<p>By looking into the structure of embeddings, we seek to understand
the shape these might approach. To understand them, we represent them
using dimensionality reduction techniques. <!----> # Dimensionality
Reduction We employ the most commonly used dimensionality reduction
techniques:</p>
<ul>
<li><strong>Linear</strong>
<ul>
<li><strong>Singular Value Decomposition</strong>
<ul>
<li>decomposes a matrix as <span
class="math inline"><em>A</em>‚ÄÑ=‚ÄÑ<em>U</em><em>Œ£</em><em>V</em><sup><em>T</em></sup></span>
(rotation, stretch, rotation). <span
class="math inline"><em>Œ£</em></span> contains the singular values,
which <strong>measure the data stretch along each principal
direction</strong>.
<ul>
<li>We then sort the features by their singular values to get the most
significant ones.</li>
</ul></li>
</ul></li>
<li><strong>Principal Component Analysis</strong> - like SVD, but
centers the features (subtracts the mean) first. As a consequence, the
singular values correspond to <strong>the standard deviations along each
principal component</strong>. - has cleaner statistical interpretation,
but can destroy non-centered structures</li>
</ul></li>
<li><strong>Non-Linear</strong>
<ul>
<li><strong>t-SNE</strong> - Models proximity relationships in the data
as a probability distribution - Recreates the data points in a
lower-dimensional space, optimizing them through gradient descent to
have the same distribution</li>
<li><strong>UMAP</strong>
<ul>
<li>preserves both local and global structure using topological data
analysis. Faster than t-SNE with better scalability.</li>
<li>more stable results, better preservation of global relationships
<!----> # Number Semantics</li>
</ul></li>
</ul></li>
<li>We also have an opportunity to check semantics in a way that crosses
the symbolic barrier.</li>
<li>We can relate the symbols themselves (0, 1, 2, ‚Ä¶, 999) to the
<strong>numeric components that constitute the embeddings</strong></li>
<li>We explore this idea by checking individual features for all the
integer embeddings and their correlation with important mathematical
sequences:
<ul>
<li><span
class="math inline"><em>n</em><sub><em>i</em></sub>‚ÄÑ=‚ÄÑ<em>i</em></span>
(the numbers themselves)</li>
<li><span
class="math inline"><em>n</em><sub><em>i</em></sub>‚ÄÑ=‚ÄÑlog‚ÄÜ(<em>i</em>)</span></li>
<li>Prime numbers</li>
<li>Fibonacci numbers</li>
<li>Triangular numbers</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python marimo"><code class="sourceCode python"></code></pre></div>
</section>
    </div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/plugin/notes/notes.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/plugin/search/search.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.2.1/plugin/zoom/zoom.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // reveal.js plugins
        plugins: [
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
